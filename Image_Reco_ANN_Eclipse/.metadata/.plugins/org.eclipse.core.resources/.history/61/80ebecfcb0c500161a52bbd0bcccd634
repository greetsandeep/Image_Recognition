package artificialneuralnetworks;

public class Network {
	int inputs;
	int hidden;
	int outputs;
	double eta;
	double momentum;
	double hiddenWeights[][];
	double outputWeights[][];
	double deltaK[];
	double deltaH[];
	
	/**
	 * @param inputs : No. of inputs to the network 
	 * @param hidden : No. of hidden layers in the network
	 * @param outputs : No. of output layers in the network
	 * @param eta : Learning rate of the network
	 * @param momentum : Momentum of the network
	 */
	Network(int inputs, int hidden, int outputs, double eta, double momentum){
		this.inputs = inputs;
		this.hidden = hidden;
		this.outputs = outputs;
		this.eta = eta;
		this.momentum = momentum;
		
		hiddenWeights = new double[hidden][inputs];
		outputWeights = new double[outputs][hidden];
		deltaK = new double[outputs];
		deltaH = new double[hidden];
		
		/* Initialize weight vectors with small random weights */
		for(int i = 0;i<hidden;i++){
			for(int j=0;j<inputs;j++){
				hiddenWeights[i][j] = Math.random()*0.1 - 0.05;
			}
		}
		
		for(int i = 0;i<outputs;i++){
			for(int j = 0;j<hidden;j++){
				outputWeights[i][j] = Math.random()*0.1 - 0.05;
			}
		}
	}
	
	/**
	 * @param input : The input vector
	 * @param target : The target output vector
	 */
	void updateWeights(double input[], double target[]){
		double op[] = networkHiddenOutput(input, 0);
		double hop[] = networkHiddenOutput(input, 1);
		double deltaW = 0.0;
		for(int k=0;k<outputs;k++){
			deltaK[k] = op[k]*(1-op[k])*(target[k]-op[k]);
		}
		for(int h = 0;h<hidden;h++){
			for(int k =0;k<outputs;k++){
				deltaH[h] += outputWeights[k][h]*deltaK[k];
			}
			deltaH[h] = deltaH[h]*hop[h]*(1-hop[h]);
		}
		
		for(int i=0;i<outputs;i++){
			for(int j=0;j<hidden;j++){
				outputWeights[i][j] += eta*hop[j]*deltaK[i];
			}
		}
		
		for(int i=0;i<hidden;i++){
			for(int j=0;j<inputs;j++){
				hiddenWeights[i][j] += eta*input[j]*deltaH[i];
			}
		}
	}
	
	/**
	 * @param input : The input vector
	 * @param flag : Indicates what to return. flag = 0 returns the output of the network, flag = 1 returns the
	 * 					output of the hidden layer
	 * @return : Network output vector or output of the hidden layer 
	 */
	double[] networkHiddenOutput(double input[], int flag){
		double[] output = new double[outputs];
		double[] hiddenOp = new double[hidden];
		
		for(int i = 0; i<hidden;i++){
			hiddenOp[i] = sigmoidOutput(dot(hiddenWeights[i], input));
		}
		
		for(int i = 0; i<outputs; i++){
			output[i] = sigmoidOutput(dot(outputWeights[i], hiddenOp));
		}
		if(flag == 0)
			return output;
		else
			return hiddenOp;
	}
	
	/**
	 * @param z : Input on which sigmoid function is to be applied
	 * @return : Output after applying sigmoid function on the input
	 */
	double sigmoidOutput(double z){
		double sig;
		sig = 1/(1+Math.exp(-1*z));
		return sig;
	}
	
	/**
	 * @param weight : Weight vector
	 * @param input : input vector
	 * @return : dot product of the vector
	 */
	double dot(double weight[], double input[]){
		double result=0.0;
		
		if(weight.length != input.length){
			System.err.println("Incompatible arguments");
			return -99999999;
		}
		else{
			for(int i=0;i<weight.length;i++){
				result += weight[i]*input[i];
			}
		}
		
		return result;
	}
}
